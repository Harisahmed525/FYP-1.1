/**
 * Safe OpenAI Client Wrapper
 * - Stable error handling
 * - Supports fallback models
 * - Works perfectly with questionGenerator.js
 */

const OpenAI = require("openai");

// Load API key
const OPENAI_KEY = process.env.OPENAI_API_KEY;

// Initialize client
let client = null;

if (OPENAI_KEY) {
  try {
    client = new OpenAI({ apiKey: OPENAI_KEY });
    console.log("‚úÖ OpenAI client initialized");
  } catch (err) {
    console.error("‚ùå Failed to initialize OpenAI client:", err.message);
  }
} else {
  console.warn("‚ö†Ô∏è OPENAI_API_KEY missing ‚Üí AI features disabled");
}

/**
 * Preferred model list (fallback mechanism)
 */
const MODEL_PRIORITY = [
  "gpt-4o-mini",
  "gpt-4o-mini-chat",
  "gpt-4o",
  "gpt-3.5-turbo"
];

/**
 * Safe wrapper for Chat Completions
 */
async function safeChatCompletion(messages, model = MODEL_PRIORITY[0]) {
  if (!client) {
    return {
      error: true,
      message: "OpenAI API key is missing."
    };
  }

  let lastError = null;

  for (const currentModel of MODEL_PRIORITY) {
    try {
      console.log(`üîµ Trying model: ${currentModel}`);

      const response = await client.chat.completions.create({
        model: currentModel,
        messages,
        temperature: 0.8
      });

      // Defensive check for unexpected OpenAI response format
      const content =
        response?.choices?.[0]?.message?.content || null;

      if (!content) {
        throw new Error("OpenAI response missing content field.");
      }

      console.log(`üü¢ Model succeeded: ${currentModel}`);
      return { error: false, content };

    } catch (err) {
      console.error(`‚ùå Model failed (${currentModel}):`, err.message);
      lastError = err;
    }
  }

  // All models failed
  return {
    error: true,
    message: "All OpenAI models failed.",
    details: lastError?.message || "Unknown error"
  };
}

module.exports = {
  openaiClient: client,
  safeChatCompletion
};
